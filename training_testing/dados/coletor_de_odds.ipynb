{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 23:35:23,480 - INFO - Arquivo não encontrado - iniciando do zero\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'event_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Enzo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'event_id'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 143\u001b[39m\n\u001b[32m    140\u001b[39m     logger.info(\u001b[33m\"\u001b[39m\u001b[33mArquivo não encontrado - iniciando do zero\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    142\u001b[39m df_events = pd.read_excel(\u001b[33m'\u001b[39m\u001b[33mtest_dataset.xlsx\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m new_events = df_events[~\u001b[43mdf_events\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mevent_id\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.isin(existing_ids)]\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m new_events.empty:\n\u001b[32m    146\u001b[39m     logger.info(\u001b[33m\"\u001b[39m\u001b[33mNenhum novo evento para processar\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Enzo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Enzo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'event_id'"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Coletor de Odds - Versão Notebook\n",
    "# \n",
    "# **Funcionalidades:**\n",
    "# 1. Processa apenas eventos não coletados\n",
    "# 2. Para após 3 erros 429 consecutivos\n",
    "# 3. Salva progresso automaticamente\n",
    "# 4. Exibe progresso em tempo real\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import logging\n",
    "from tqdm.notebook import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Configurações Iniciais\n",
    "\n",
    "# %%\n",
    "# Configurações da API\n",
    "TOKEN = \"183604-pWN7flhoAsWGu8\"\n",
    "URL_ODDS = \"https://api.b365api.com/v2/event/odds\"\n",
    "\n",
    "# Controle de erros 429\n",
    "MAX_429_ERRORS = 3\n",
    "current_429_errors = 0\n",
    "stop_execution = False\n",
    "\n",
    "# Configurar logging\n",
    "logging.basicConfig(level=logger.info, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Funções Principais\n",
    "\n",
    "# %%\n",
    "def make_request(event_id):\n",
    "    global current_429_errors, stop_execution\n",
    "    \n",
    "    params = {\n",
    "        'token': TOKEN,\n",
    "        'event_id': event_id\n",
    "    }\n",
    "    \n",
    "    for attempt in range(5):\n",
    "        if stop_execution:\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(URL_ODDS, params=params, timeout=15)\n",
    "            \n",
    "            if response.status_code == 429:\n",
    "                current_429_errors += 1\n",
    "                logger.warning(f\"Erro 429 detectado ({current_429_errors}/{MAX_429_ERRORS})\")\n",
    "                \n",
    "                if current_429_errors >= MAX_429_ERRORS:\n",
    "                    stop_execution = True\n",
    "                    logger.error(\"Limite de erros 429 atingido! Interrompendo...\")\n",
    "                    return None\n",
    "                \n",
    "                wait_time = (2 ** attempt) + 2\n",
    "                time.sleep(wait_time)\n",
    "                continue\n",
    "                \n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Erro na tentativa {attempt+1}: {str(e)}\")\n",
    "            time.sleep(2 ** attempt)\n",
    "    \n",
    "    return None\n",
    "\n",
    "# %%\n",
    "def process_odds(event_id):\n",
    "    global stop_execution\n",
    "    \n",
    "    if stop_execution:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        data = make_request(event_id)\n",
    "        \n",
    "        if not data or data.get('success') != 1:\n",
    "            return None\n",
    "        \n",
    "        odds = data.get('results', {}).get('odds', {})\n",
    "        processed = {'event_id': event_id}\n",
    "        \n",
    "        # Processar mercados\n",
    "        for market in ['1_1', '1_2', '1_3']:\n",
    "            market_data = odds.get(market, [])\n",
    "            \n",
    "            # Selecionar odd mais relevante\n",
    "            valid_odds = [o for o in market_data if o.get('ss') == '0-0']\n",
    "            if not valid_odds:\n",
    "                valid_odds = [o for o in market_data if not o.get('ss')]\n",
    "            \n",
    "            if valid_odds:\n",
    "                best_odd = max(valid_odds, key=lambda x: int(x.get('add_time', 0)))\n",
    "                prefix = f\"{market}_\"\n",
    "                \n",
    "                if market == '1_3':\n",
    "                    processed.update({\n",
    "                        f\"{prefix}over\": best_odd.get('over_od'),\n",
    "                        f\"{prefix}under\": best_odd.get('under_od'),\n",
    "                        f\"{prefix}handicap\": best_odd.get('handicap')\n",
    "                    })\n",
    "                else:\n",
    "                    processed.update({\n",
    "                        f\"{prefix}home\": best_odd.get('home_od'),\n",
    "                        f\"{prefix}draw\": best_odd.get('draw_od'),\n",
    "                        f\"{prefix}away\": best_odd.get('away_od')\n",
    "                    })\n",
    "                \n",
    "                # Converter timestamp\n",
    "                ts = int(best_odd.get('add_time', 0))\n",
    "                processed[f\"{prefix}time\"] = datetime.fromtimestamp(ts, tz=timezone.utc).strftime('%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "        return processed\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro no evento {event_id}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Carregar Dados e Executar\n",
    "\n",
    "# %%\n",
    "# Carregar datasets\n",
    "try:\n",
    "    df_existing = pd.read_excel('dados_com_odds_train_test.xlsx')\n",
    "    existing_ids = set(df_existing['event_id'])\n",
    "    logger.info(f\"Carregados {len(df_existing)} eventos existentes\")\n",
    "except FileNotFoundError:\n",
    "    df_existing = pd.DataFrame()\n",
    "    existing_ids = set()\n",
    "    logger.info(\"Arquivo não encontrado - iniciando do zero\")\n",
    "\n",
    "df_events = pd.read_excel('test_dataset.xlsx')\n",
    "new_events = df_events[~df_events['event_id'].isin(existing_ids)]\n",
    "\n",
    "if new_events.empty:\n",
    "    logger.info(\"Nenhum novo evento para processar\")\n",
    "else:\n",
    "    logger.info(f\"Encontrados {len(new_events)} novos eventos\")\n",
    "\n",
    "# %%\n",
    "# Executar coleta com progresso\n",
    "results = []\n",
    "batch_size = 10  # Reduza se encontrar erros 429\n",
    "\n",
    "with tqdm(total=len(new_events), desc=\"Processando Odds\") as pbar:\n",
    "    with ThreadPoolExecutor(max_workers=3) as executor:\n",
    "        futures = {executor.submit(process_odds, row.event_id): row for _, row in new_events.iterrows()}\n",
    "        \n",
    "        for future in as_completed(futures):\n",
    "            if stop_execution:\n",
    "                executor.shutdown(wait=False, cancel_futures=True)\n",
    "                break\n",
    "                \n",
    "            result = future.result()\n",
    "            if result:\n",
    "                results.append(result)\n",
    "                pbar.update(1)\n",
    "                \n",
    "            # Salvar progresso a cada batch\n",
    "            if len(results) % batch_size == 0:\n",
    "                df_temp = pd.DataFrame(results)\n",
    "                if not df_temp.empty:\n",
    "                    df_final = pd.concat([df_existing, df_temp], ignore_index=True)\n",
    "                    df_final.to_csv('dados_com_odds.csv', index=False)\n",
    "                    logger.info(f\"Progresso salvo - {len(df_final)} eventos\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Salvamento Final e Resultados\n",
    "\n",
    "# %%\n",
    "# Consolidar dados finais\n",
    "if results:\n",
    "    df_final = pd.concat([df_existing, pd.DataFrame(results)], ignore_index=True)\n",
    "    df_final.to_csv('dados_com_odds.csv', index=False)\n",
    "    df_final.to_excel('dados_com_odds.xlsx', index=False)\n",
    "    logger.info(f\"Processo completo! Total de eventos: {len(df_final)}\")\n",
    "    \n",
    "    # Exibir amostra\n",
    "    display(df_final.tail(3))\n",
    "else:\n",
    "    logger.info(\"Nenhum novo dado foi processado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-13 10:56:06,074 - INFO - Total de eventos: 5355\n",
      "2025-04-13 10:56:06,075 - INFO - Eventos a processar: 5355\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35738930170043f391c3d4eed1a72a80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processando Odds:   0%|          | 0/5355 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-13 10:56:07,087 - WARNING - Erro 429 detectado (1/3)\n",
      "2025-04-13 10:56:07,093 - WARNING - Erro 429 detectado (2/3)\n",
      "2025-04-13 10:56:07,137 - WARNING - Erro 429 detectado (3/3)\n",
      "2025-04-13 10:56:07,139 - ERROR - Limite de erros 429 atingido! Interrompendo...\n",
      "2025-04-13 10:56:10,096 - INFO - Nenhum dado novo foi processado\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Coletor de Odds - Versão Notebook (Excel)\n",
    "# \n",
    "# **Modificações principais:**\n",
    "# 1. Leitura de arquivo Excel como entrada\n",
    "# 2. Adição automática de novas colunas\n",
    "# 3. Salvamento em Excel mantendo estrutura original\n",
    "# 4. Processamento apenas de registros incompletos\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import logging\n",
    "from tqdm.notebook import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Configurações Iniciais\n",
    "\n",
    "# %%\n",
    "# Configurações da API\n",
    "TOKEN = \"183604-pWN7flhoAsWGu8\"\n",
    "URL_ODDS = \"https://api.b365api.com/v2/event/odds\"\n",
    "\n",
    "# Controle de erros 429\n",
    "MAX_429_ERRORS = 3\n",
    "current_429_errors = 0\n",
    "stop_execution = False\n",
    "\n",
    "# Lista de novas colunas\n",
    "NEW_COLUMNS = [\n",
    "    '1_1_home', '1_1_draw', '1_1_away', '1_1_time',\n",
    "    '1_2_home', '1_2_draw', '1_2_away', '1_2_time',\n",
    "    '1_3_over', '1_3_under', '1_3_handicap', '1_3_time'\n",
    "]\n",
    "\n",
    "# Configurar logging\n",
    "logging.basicConfig(level=logger.info, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Funções Principais (Mesmas do Original)\n",
    "\n",
    "# %%\n",
    "def make_request(event_id):\n",
    "    global current_429_errors, stop_execution\n",
    "    \n",
    "    params = {\n",
    "        'token': TOKEN,\n",
    "        'event_id': event_id\n",
    "    }\n",
    "    \n",
    "    for attempt in range(5):\n",
    "        if stop_execution:\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(URL_ODDS, params=params, timeout=15)\n",
    "            \n",
    "            if response.status_code == 429:\n",
    "                current_429_errors += 1\n",
    "                logger.warning(f\"Erro 429 detectado ({current_429_errors}/{MAX_429_ERRORS})\")\n",
    "                \n",
    "                if current_429_errors >= MAX_429_ERRORS:\n",
    "                    stop_execution = True\n",
    "                    logger.error(\"Limite de erros 429 atingido! Interrompendo...\")\n",
    "                    return None\n",
    "                \n",
    "                wait_time = (2 ** attempt) + 2\n",
    "                time.sleep(wait_time)\n",
    "                continue\n",
    "                \n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Erro na tentativa {attempt+1}: {str(e)}\")\n",
    "            time.sleep(2 ** attempt)\n",
    "    \n",
    "    return None\n",
    "\n",
    "# %%\n",
    "def process_odds(event_id):\n",
    "    global stop_execution\n",
    "    \n",
    "    if stop_execution:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        data = make_request(event_id)\n",
    "        \n",
    "        if not data or data.get('success') != 1:\n",
    "            return None\n",
    "        \n",
    "        odds = data.get('results', {}).get('odds', {})\n",
    "        processed = {'event_id': event_id}\n",
    "        \n",
    "        # Processar mercados\n",
    "        for market in ['1_1', '1_2', '1_3']:\n",
    "            market_data = odds.get(market, [])\n",
    "            \n",
    "            # Selecionar odd mais relevante\n",
    "            valid_odds = [o for o in market_data if o.get('ss') == '0-0']\n",
    "            if not valid_odds:\n",
    "                valid_odds = [o for o in market_data if not o.get('ss')]\n",
    "            \n",
    "            if valid_odds:\n",
    "                best_odd = max(valid_odds, key=lambda x: int(x.get('add_time', 0)))\n",
    "                prefix = f\"{market}_\"\n",
    "                \n",
    "                if market == '1_3':\n",
    "                    processed.update({\n",
    "                        f\"{prefix}over\": best_odd.get('over_od'),\n",
    "                        f\"{prefix}under\": best_odd.get('under_od'),\n",
    "                        f\"{prefix}handicap\": best_odd.get('handicap')\n",
    "                    })\n",
    "                else:\n",
    "                    processed.update({\n",
    "                        f\"{prefix}home\": best_odd.get('home_od'),\n",
    "                        f\"{prefix}draw\": best_odd.get('draw_od'),\n",
    "                        f\"{prefix}away\": best_odd.get('away_od')\n",
    "                    })\n",
    "                \n",
    "                # Converter timestamp\n",
    "                ts = int(best_odd.get('add_time', 0))\n",
    "                processed[f\"{prefix}time\"] = datetime.fromtimestamp(ts, tz=timezone.utc).strftime('%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "        return processed\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro no evento {event_id}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Carregar Dados e Executar (Ajustado para Excel)\n",
    "\n",
    "# %%\n",
    "# Carregar dataset\n",
    "try:\n",
    "    df_events = pd.read_excel('test_dataset.xlsx')\n",
    "    \n",
    "    # Adicionar colunas faltantes\n",
    "    for col in NEW_COLUMNS:\n",
    "        if col not in df_events.columns:\n",
    "            df_events[col] = None\n",
    "            \n",
    "    # Identificar eventos não processados\n",
    "    mask_na = df_events[NEW_COLUMNS].isna().all(axis=1)\n",
    "    event_ids_to_process = df_events[mask_na]['event_id'].tolist()\n",
    "    \n",
    "    logger.info(f\"Total de eventos: {len(df_events)}\")\n",
    "    logger.info(f\"Eventos a processar: {len(event_ids_to_process)}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    logger.error(\"Arquivo 'test_dataset.xlsx' não encontrado!\")\n",
    "    exit()\n",
    "\n",
    "if not event_ids_to_process:\n",
    "    logger.info(\"Nenhum novo evento para processar\")\n",
    "    exit()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Execução do Processamento\n",
    "\n",
    "# %%\n",
    "results = []\n",
    "batch_size = 5  # Reduzido para arquivos Excel\n",
    "\n",
    "with tqdm(total=len(event_ids_to_process), desc=\"Processando Odds\") as pbar:\n",
    "    with ThreadPoolExecutor(max_workers=3) as executor:\n",
    "        futures = {executor.submit(process_odds, eid): eid for eid in event_ids_to_process}\n",
    "        \n",
    "        for future in as_completed(futures):\n",
    "            if stop_execution:\n",
    "                executor.shutdown(wait=False, cancel_futures=True)\n",
    "                break\n",
    "                \n",
    "            result = future.result()\n",
    "            if result:\n",
    "                results.append(result)\n",
    "                pbar.update(1)\n",
    "                \n",
    "            # Salvamento parcial\n",
    "            if len(results) % batch_size == 0 and results:\n",
    "                partial_df = pd.DataFrame(results)\n",
    "                df_events.set_index('event_id', inplace=True)\n",
    "                df_events.update(partial_df.set_index('event_id'))\n",
    "                df_events.reset_index(inplace=True)\n",
    "                \n",
    "                try:\n",
    "                    df_events.to_csv('temp_progress.csv', index=False)\n",
    "                    logger.info(\"Progresso salvo temporariamente\")\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"Erro ao salvar progresso: {str(e)}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Salvamento Final\n",
    "\n",
    "# %%\n",
    "if results:\n",
    "    # Atualizar dataframe principal\n",
    "    final_df = pd.DataFrame(results)\n",
    "    df_events.set_index('event_id', inplace=True)\n",
    "    df_events.update(final_df.set_index('event_id'))\n",
    "    df_events.reset_index(inplace=True)\n",
    "    \n",
    "    # Salvar arquivo final\n",
    "    output_file = 'df_merged.csv'\n",
    "    df_events.to_csv(output_file, index=False)\n",
    "    \n",
    "    # Resultados\n",
    "    logger.info(f\"Processo completo! Arquivo salvo como: {output_file}\")\n",
    "    print(\"\\nAmostra dos dados processados:\")\n",
    "    display(df_events[['event_id'] + NEW_COLUMNS].tail(3))\n",
    "    \n",
    "    # Limpar arquivo temporário\n",
    "    try:\n",
    "        os.remove('temp_progress.xlsx')\n",
    "    except:\n",
    "        pass\n",
    "else:\n",
    "    logger.info(\"Nenhum dado novo foi processado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-13 09:50:13,184 - INFO - Dataset carregado: 26884 registros\n",
      "2025-04-13 09:50:13,185 - INFO - Registros incompletos detectados: 13129\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66be8886eb314653ac5d63f66a24def6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Coletando Odds:   0%|          | 0/13129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Enzo\\AppData\\Local\\Temp\\ipykernel_12700\\1938596793.py:214: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[nan nan nan ... nan nan nan]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_atualizado.update(pd.DataFrame(resultados).set_index('event_id'))\n",
      "2025-04-13 09:50:23,566 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 09:50:33,140 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 09:50:44,365 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 09:50:54,502 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 09:51:05,405 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 09:51:18,540 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 09:51:37,347 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 09:51:51,015 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 09:52:00,152 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 09:52:09,264 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 09:52:18,503 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 09:52:27,809 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 09:52:37,047 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 09:52:46,416 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 09:52:55,499 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 09:53:04,713 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 09:53:13,998 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 09:53:23,390 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 09:53:32,842 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 09:53:41,877 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 09:53:51,097 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 09:54:00,548 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 09:54:09,614 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 09:54:13,223 - WARNING - Tentativa 1/5 falhou: 520 Server Error:  for url: https://api.b365api.com/v2/event/odds?token=183604-pWN7flhoAsWGu8&event_id=9597631\n",
      "2025-04-13 09:54:18,923 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 09:54:27,969 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 09:54:37,197 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 09:54:46,575 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 09:54:55,804 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 09:55:05,325 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 09:55:14,734 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 09:55:23,559 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 09:55:32,676 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 09:55:41,080 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 09:55:49,534 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 09:55:58,006 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 09:56:07,601 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 09:56:16,188 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 09:56:25,010 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 09:56:35,006 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 09:56:44,556 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 09:56:54,762 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 09:57:04,405 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 09:57:14,275 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 09:57:24,917 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 09:57:39,656 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 09:57:58,219 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 09:58:14,750 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 09:58:29,939 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 09:58:45,693 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 09:59:00,052 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 09:59:14,864 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 09:59:32,237 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 09:59:49,116 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:00:05,409 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:00:22,743 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:00:38,901 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:00:55,238 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:01:10,490 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:01:23,440 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:01:36,621 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:01:49,940 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:02:03,351 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:02:16,908 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:02:31,419 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:02:45,701 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:03:00,466 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:03:22,833 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:03:43,844 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:04:07,143 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:04:32,706 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:04:49,653 - WARNING - Tentativa 1/5 falhou: 500 Server Error: Internal Server Error for url: https://api.b365api.com/v2/event/odds?token=183604-pWN7flhoAsWGu8&event_id=9614089\n",
      "2025-04-13 10:04:55,097 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:05:16,253 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:05:36,823 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:05:58,051 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:06:18,983 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:06:40,543 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:07:02,110 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:07:22,033 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:07:44,272 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:08:03,822 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:08:18,003 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:08:31,129 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:08:44,743 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:09:02,626 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:09:19,586 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:09:39,831 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:10:01,902 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:10:21,893 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:10:37,019 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:10:47,623 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:10:59,902 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:11:11,891 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:11:23,803 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:11:35,364 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:11:46,872 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:11:58,232 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:12:09,937 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:12:21,093 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:12:32,510 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:12:44,009 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:12:55,951 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:13:11,029 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:13:25,036 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:13:38,283 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:13:51,562 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:14:05,356 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:14:18,299 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:14:33,702 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:14:48,658 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:15:04,058 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:15:19,479 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:15:35,030 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:15:50,639 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:16:08,766 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:16:31,291 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:16:54,307 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:17:13,901 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:17:32,536 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:17:54,144 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:18:11,148 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:18:25,531 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:18:44,103 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:19:02,839 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:19:20,664 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:19:40,133 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:20:00,392 - WARNING - Tentativa 1/5 falhou: 502 Server Error: Bad Gateway for url: https://api.b365api.com/v2/event/odds?token=183604-pWN7flhoAsWGu8&event_id=9634646\n",
      "2025-04-13 10:20:00,577 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:20:21,667 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:20:42,800 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:21:05,175 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:21:26,142 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:21:47,475 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:22:09,672 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:22:30,994 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:22:51,517 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:23:13,214 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:23:36,174 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:23:56,716 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:24:13,511 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:24:32,242 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:24:54,679 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:25:16,702 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:25:36,894 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:25:55,702 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:26:14,788 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:26:31,865 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:26:49,364 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:27:08,067 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:27:25,756 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:27:45,436 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:28:03,985 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:28:23,265 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:28:42,111 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:28:57,404 - WARNING - Tentativa 1/5 falhou: 520 Server Error:  for url: https://api.b365api.com/v2/event/odds?token=183604-pWN7flhoAsWGu8&event_id=9646845\n",
      "2025-04-13 10:29:01,534 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:29:21,383 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:29:34,968 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:29:39,105 - WARNING - Tentativa 1/5 falhou: 502 Server Error: Bad Gateway for url: https://api.b365api.com/v2/event/odds?token=183604-pWN7flhoAsWGu8&event_id=9647380\n",
      "2025-04-13 10:29:49,436 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:30:06,126 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:30:21,414 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:30:36,164 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:30:50,319 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:31:04,919 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:31:19,440 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:31:34,190 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:31:49,292 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:32:03,513 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:32:18,069 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:32:33,331 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:32:47,520 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:33:02,319 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:33:17,561 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:33:33,699 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:33:50,099 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:34:06,066 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:34:19,756 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:34:32,958 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:34:46,322 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:34:59,978 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:35:04,000 - WARNING - Tentativa 1/5 falhou: 502 Server Error: Bad Gateway for url: https://api.b365api.com/v2/event/odds?token=183604-pWN7flhoAsWGu8&event_id=9654130\n",
      "2025-04-13 10:35:12,985 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:35:26,349 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:35:39,567 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:35:53,181 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:36:07,337 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:36:25,404 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:36:42,196 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:37:00,041 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:37:20,069 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:37:42,838 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:38:03,986 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:38:10,634 - WARNING - Erro 429 (#1/3)\n",
      "2025-04-13 10:38:11,003 - WARNING - Erro 429 (#2/3)\n",
      "2025-04-13 10:38:11,141 - WARNING - Erro 429 (#3/3)\n",
      "2025-04-13 10:38:11,157 - ERROR - Limite de erros 429 atingido! Abortando...\n",
      "2025-04-13 10:38:11,189 - ERROR - Limite de erros 429 atingido! Abortando...\n",
      "2025-04-13 10:38:23,947 - INFO - Progresso temporário salvo em temp_progress.xlsx\n",
      "2025-04-13 10:38:24,072 - ERROR - Erro ao salvar: No engine for filetype: 'csv'\n",
      "2025-04-13 10:38:24,076 - INFO - Processo concluído! 945 novos registros processados\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Visualização dos dados:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>1_1_home</th>\n",
       "      <th>1_1_draw</th>\n",
       "      <th>1_1_away</th>\n",
       "      <th>1_1_time</th>\n",
       "      <th>1_2_home</th>\n",
       "      <th>1_2_draw</th>\n",
       "      <th>1_2_away</th>\n",
       "      <th>1_2_time</th>\n",
       "      <th>1_3_over</th>\n",
       "      <th>1_3_under</th>\n",
       "      <th>1_3_handicap</th>\n",
       "      <th>1_3_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26881</th>\n",
       "      <td>9790071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26882</th>\n",
       "      <td>9790070</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26883</th>\n",
       "      <td>9789627</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       event_id 1_1_home 1_1_draw 1_1_away 1_1_time 1_2_home 1_2_draw  \\\n",
       "26881   9790071      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "26882   9790070      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "26883   9789627      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "\n",
       "      1_2_away 1_2_time 1_3_over 1_3_under 1_3_handicap 1_3_time  \n",
       "26881      NaN      NaN      NaN       NaN          NaN      NaN  \n",
       "26882      NaN      NaN      NaN       NaN          NaN      NaN  \n",
       "26883      NaN      NaN      NaN       NaN          NaN      NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Coletor de Odds - Versão Final (Excel)\n",
    "# \n",
    "# **Funcionalidades:**\n",
    "# 1. Processamento exclusivo de arquivos Excel (.xlsx)\n",
    "# 2. Adição automática de colunas necessárias\n",
    "# 3. Salvamento incremental seguro\n",
    "# 4. Detecção inteligente de registros incompletos\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import logging\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Configurações Iniciais\n",
    "\n",
    "# %%\n",
    "# Configurações da API\n",
    "TOKEN = \"183604-pWN7flhoAsWGu8\"\n",
    "URL_ODDS = \"https://api.b365api.com/v2/event/odds\"\n",
    "\n",
    "# Controles de execução\n",
    "MAX_429_ERRORS = 3\n",
    "current_429_errors = 0\n",
    "stop_execution = False\n",
    "\n",
    "# Lista de colunas de odds\n",
    "COLUNAS_ODDS = [\n",
    "    '1_1_home', '1_1_draw', '1_1_away', '1_1_time',\n",
    "    '1_2_home', '1_2_draw', '1_2_away', '1_2_time',\n",
    "    '1_3_over', '1_3_under', '1_3_handicap', '1_3_time'\n",
    "]\n",
    "\n",
    "# Configuração do logging\n",
    "logging.basicConfig(\n",
    "    level=logger.info,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('coletor_odds.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Funções de Processamento\n",
    "\n",
    "# %%\n",
    "def fazer_requisicao(event_id):\n",
    "    global current_429_errors, stop_execution\n",
    "    \n",
    "    params = {\n",
    "        'token': TOKEN,\n",
    "        'event_id': event_id\n",
    "    }\n",
    "    \n",
    "    for tentativa in range(5):\n",
    "        if stop_execution:\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            resposta = requests.get(URL_ODDS, params=params, timeout=15)\n",
    "            \n",
    "            if resposta.status_code == 429:\n",
    "                current_429_errors += 1\n",
    "                logger.warning(f\"Erro 429 (#{current_429_errors}/{MAX_429_ERRORS})\")\n",
    "                \n",
    "                if current_429_errors >= MAX_429_ERRORS:\n",
    "                    stop_execution = True\n",
    "                    logger.error(\"Limite de erros 429 atingido! Abortando...\")\n",
    "                    return None\n",
    "                \n",
    "                espera = (2 ** tentativa) + 2\n",
    "                time.sleep(espera)\n",
    "                continue\n",
    "                \n",
    "            resposta.raise_for_status()\n",
    "            return resposta.json()\n",
    "            \n",
    "        except Exception as erro:\n",
    "            logger.warning(f\"Tentativa {tentativa+1}/5 falhou: {str(erro)}\")\n",
    "            time.sleep(2 ** tentativa)\n",
    "    \n",
    "    return None\n",
    "\n",
    "# %%\n",
    "def processar_odds(event_id):\n",
    "    global stop_execution\n",
    "    \n",
    "    if stop_execution:\n",
    "        return None\n",
    "    \n",
    "def processar_odds(event_id):\n",
    "    global stop_execution\n",
    "    \n",
    "    if stop_execution:\n",
    "        return None\n",
    "\n",
    "    # Inicializar o dicionário com valores padrão '-'\n",
    "    processado = {'event_id': event_id}\n",
    "    for coluna in COLUNAS_ODDS:\n",
    "        processado[coluna] = '-'\n",
    "\n",
    "    try:\n",
    "        dados = fazer_requisicao(event_id)\n",
    "        \n",
    "        if not dados or dados.get('success') != 1:\n",
    "            return processado  # Retorna com '-' preenchido\n",
    "\n",
    "        odds = dados.get('results', {}).get('odds', {})\n",
    "\n",
    "        for mercado in ['1_1', '1_2', '1_3']:\n",
    "            dados_mercado = odds.get(mercado, [])\n",
    "\n",
    "            odds_validas = [o for o in dados_mercado if o.get('ss') == '0-0'] or \\\n",
    "                           [o for o in dados_mercado if not o.get('ss')]\n",
    "\n",
    "            if odds_validas:\n",
    "                melhor_odd = max(odds_validas, key=lambda x: int(x.get('add_time', 0)))\n",
    "                prefixo = f\"{mercado}_\"\n",
    "\n",
    "                if mercado == '1_3':\n",
    "                    processado[f\"{prefixo}over\"] = melhor_odd.get('over_od', '-')\n",
    "                    processado[f\"{prefixo}under\"] = melhor_odd.get('under_od', '-')\n",
    "                    processado[f\"{prefixo}handicap\"] = melhor_odd.get('handicap', '-')\n",
    "                else:\n",
    "                    processado[f\"{prefixo}home\"] = melhor_odd.get('home_od', '-')\n",
    "                    processado[f\"{prefixo}draw\"] = melhor_odd.get('draw_od', '-')\n",
    "                    processado[f\"{prefixo}away\"] = melhor_odd.get('away_od', '-')\n",
    "\n",
    "                ts = int(melhor_odd.get('add_time', 0))\n",
    "                processado[f\"{prefixo}time\"] = datetime.fromtimestamp(ts, tz=timezone.utc).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        return processado\n",
    "\n",
    "    except Exception as erro:\n",
    "        logger.error(f\"Falha crítica no evento {event_id}: {str(erro)}\")\n",
    "        return processado  # Retorna com '-'\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Gerenciamento de Arquivos Excel\n",
    "\n",
    "# %%\n",
    "def carregar_dataset():\n",
    "    try:\n",
    "        df = pd.read_csv('df_merged.csv')\n",
    "        \n",
    "        # Adicionar colunas faltantes\n",
    "        for coluna in COLUNAS_ODDS:\n",
    "            if coluna not in df.columns:\n",
    "                df[coluna] = pd.NA\n",
    "                \n",
    "        # Identificar registros incompletos\n",
    "        registros_incompletos = df[df[COLUNAS_ODDS].isna().all(axis=1)]\n",
    "        ids_para_processar = registros_incompletos['event_id'].tolist()\n",
    "        \n",
    "        logger.info(f\"Dataset carregado: {len(df)} registros\")\n",
    "        logger.info(f\"Registros incompletos detectados: {len(ids_para_processar)}\")\n",
    "        \n",
    "        return df, ids_para_processar\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        logger.error(\"Erro: Arquivo 'test_dataset.xlsx' não encontrado!\")\n",
    "        exit()\n",
    "\n",
    "# %%\n",
    "def salvar_progresso(df, temp=False):\n",
    "    try:\n",
    "        arquivo = 'temp_progress.csv' if temp else 'df_merged.csv'\n",
    "        df.to_csv(arquivo, index=False)\n",
    "        logger.info(f\"Progresso {'temporário ' if temp else ''}salvo em {arquivo}\")\n",
    "    except Exception as erro:\n",
    "        logger.error(f\"Erro ao salvar: {str(erro)}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Execução Principal\n",
    "\n",
    "# %%\n",
    "# Carregar dados iniciais\n",
    "df_principal, eventos = carregar_dataset()\n",
    "\n",
    "if not eventos:\n",
    "    logger.info(\"Nenhum registro pendente para processamento\")\n",
    "    exit()\n",
    "\n",
    "# %%\n",
    "# Processamento paralelo\n",
    "resultados = []\n",
    "lote_salvamento = 5\n",
    "\n",
    "with tqdm(total=len(eventos), desc=\"Coletando Odds\") as barra_progresso:\n",
    "    with ThreadPoolExecutor(max_workers=3) as executor:\n",
    "        futures = {executor.submit(processar_odds, eid): eid for eid in eventos}\n",
    "        \n",
    "        for future in as_completed(futures):\n",
    "            if stop_execution:\n",
    "                executor.shutdown(wait=False, cancel_futures=True)\n",
    "                break\n",
    "            \n",
    "            resultado = future.result()\n",
    "            if resultado:\n",
    "                resultados.append(resultado)\n",
    "                barra_progresso.update(1)\n",
    "                \n",
    "                # Salvamento periódico\n",
    "                if len(resultados) % lote_salvamento == 0:\n",
    "                    df_atualizado = df_principal.set_index('event_id')\n",
    "                    df_atualizado.update(pd.DataFrame(resultados).set_index('event_id'))\n",
    "                    df_principal = df_atualizado.reset_index()\n",
    "                    salvar_progresso(df_principal, temp=True)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Finalização\n",
    "\n",
    "# %%\n",
    "if resultados:\n",
    "    # Atualizar dataset principal\n",
    "    df_final = pd.DataFrame(resultados)\n",
    "    df_principal = df_principal.set_index('event_id')\n",
    "    df_principal.update(df_final.set_index('event_id'))\n",
    "    df_principal = df_principal.reset_index()\n",
    "    \n",
    "    # Salvar resultado final\n",
    "    salvar_progresso(df_principal)\n",
    "    \n",
    "    # Limpar temporário\n",
    "    try:\n",
    "        os.remove('temp_progress.xlsx')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Relatório final\n",
    "    logger.info(f\"Processo concluído! {len(resultados)} novos registros processados\")\n",
    "    print(\"\\nVisualização dos dados:\")\n",
    "    display(df_principal[['event_id'] + COLUNAS_ODDS].tail(3))\n",
    "else:\n",
    "    logger.warning(\"Nenhum dado novo foi obtido\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
