{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 09:29:40,078 - INFO - Arquivo não encontrado - iniciando do zero\n",
      "2025-04-09 09:29:40,119 - INFO - Encontrados 26884 novos eventos\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 155\u001b[39m\n\u001b[32m    152\u001b[39m results = []\n\u001b[32m    153\u001b[39m batch_size = \u001b[32m10\u001b[39m  \u001b[38;5;66;03m# Reduza se encontrar erros 429\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_events\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mProcessando Odds\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[32m    156\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor(max_workers=\u001b[32m3\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[32m    157\u001b[39m         futures = {executor.submit(process_odds, row.event_id): row \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m new_events.iterrows()}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Enzo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\notebook.py:234\u001b[39m, in \u001b[36mtqdm_notebook.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    232\u001b[39m unit_scale = \u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.unit_scale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.unit_scale \u001b[38;5;129;01mor\u001b[39;00m \u001b[32m1\u001b[39m\n\u001b[32m    233\u001b[39m total = \u001b[38;5;28mself\u001b[39m.total * unit_scale \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.total \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.total\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m \u001b[38;5;28mself\u001b[39m.container = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstatus_printer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mncols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[38;5;28mself\u001b[39m.container.pbar = proxy(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    236\u001b[39m \u001b[38;5;28mself\u001b[39m.displayed = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Enzo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\notebook.py:108\u001b[39m, in \u001b[36mtqdm_notebook.status_printer\u001b[39m\u001b[34m(_, total, desc, ncols)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;66;03m# Fallback to text bar if there's no total\u001b[39;00m\n\u001b[32m    100\u001b[39m \u001b[38;5;66;03m# DEPRECATED: replaced with an 'info' style bar\u001b[39;00m\n\u001b[32m    101\u001b[39m \u001b[38;5;66;03m# if not total:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    105\u001b[39m \n\u001b[32m    106\u001b[39m \u001b[38;5;66;03m# Prepare IPython progress bar\u001b[39;00m\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m IProgress \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# #187 #451 #558 #872\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(WARN_NOIPYW)\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m total:\n\u001b[32m    110\u001b[39m     pbar = IProgress(\u001b[38;5;28mmin\u001b[39m=\u001b[32m0\u001b[39m, \u001b[38;5;28mmax\u001b[39m=total)\n",
      "\u001b[31mImportError\u001b[39m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Coletor de Odds - Versão Notebook\n",
    "# \n",
    "# **Funcionalidades:**\n",
    "# 1. Processa apenas eventos não coletados\n",
    "# 2. Para após 3 erros 429 consecutivos\n",
    "# 3. Salva progresso automaticamente\n",
    "# 4. Exibe progresso em tempo real\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import logging\n",
    "from tqdm.notebook import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Configurações Iniciais\n",
    "\n",
    "# %%\n",
    "# Configurações da API\n",
    "TOKEN = \"183604-pWN7flhoAsWGu8\"\n",
    "URL_ODDS = \"https://api.b365api.com/v2/event/odds\"\n",
    "\n",
    "# Controle de erros 429\n",
    "MAX_429_ERRORS = 3\n",
    "current_429_errors = 0\n",
    "stop_execution = False\n",
    "\n",
    "# Configurar logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Funções Principais\n",
    "\n",
    "# %%\n",
    "def make_request(event_id):\n",
    "    global current_429_errors, stop_execution\n",
    "    \n",
    "    params = {\n",
    "        'token': TOKEN,\n",
    "        'event_id': event_id\n",
    "    }\n",
    "    \n",
    "    for attempt in range(5):\n",
    "        if stop_execution:\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(URL_ODDS, params=params, timeout=15)\n",
    "            \n",
    "            if response.status_code == 429:\n",
    "                current_429_errors += 1\n",
    "                logging.warning(f\"Erro 429 detectado ({current_429_errors}/{MAX_429_ERRORS})\")\n",
    "                \n",
    "                if current_429_errors >= MAX_429_ERRORS:\n",
    "                    stop_execution = True\n",
    "                    logging.error(\"Limite de erros 429 atingido! Interrompendo...\")\n",
    "                    return None\n",
    "                \n",
    "                wait_time = (2 ** attempt) + 2\n",
    "                time.sleep(wait_time)\n",
    "                continue\n",
    "                \n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Erro na tentativa {attempt+1}: {str(e)}\")\n",
    "            time.sleep(2 ** attempt)\n",
    "    \n",
    "    return None\n",
    "\n",
    "# %%\n",
    "def process_odds(event_id):\n",
    "    global stop_execution\n",
    "    \n",
    "    if stop_execution:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        data = make_request(event_id)\n",
    "        \n",
    "        if not data or data.get('success') != 1:\n",
    "            return None\n",
    "        \n",
    "        odds = data.get('results', {}).get('odds', {})\n",
    "        processed = {'event_id': event_id}\n",
    "        \n",
    "        # Processar mercados\n",
    "        for market in ['1_1', '1_2', '1_3']:\n",
    "            market_data = odds.get(market, [])\n",
    "            \n",
    "            # Selecionar odd mais relevante\n",
    "            valid_odds = [o for o in market_data if o.get('ss') == '0-0']\n",
    "            if not valid_odds:\n",
    "                valid_odds = [o for o in market_data if not o.get('ss')]\n",
    "            \n",
    "            if valid_odds:\n",
    "                best_odd = max(valid_odds, key=lambda x: int(x.get('add_time', 0)))\n",
    "                prefix = f\"{market}_\"\n",
    "                \n",
    "                if market == '1_3':\n",
    "                    processed.update({\n",
    "                        f\"{prefix}over\": best_odd.get('over_od'),\n",
    "                        f\"{prefix}under\": best_odd.get('under_od'),\n",
    "                        f\"{prefix}handicap\": best_odd.get('handicap')\n",
    "                    })\n",
    "                else:\n",
    "                    processed.update({\n",
    "                        f\"{prefix}home\": best_odd.get('home_od'),\n",
    "                        f\"{prefix}draw\": best_odd.get('draw_od'),\n",
    "                        f\"{prefix}away\": best_odd.get('away_od')\n",
    "                    })\n",
    "                \n",
    "                # Converter timestamp\n",
    "                ts = int(best_odd.get('add_time', 0))\n",
    "                processed[f\"{prefix}time\"] = datetime.fromtimestamp(ts, tz=timezone.utc).strftime('%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "        return processed\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Erro no evento {event_id}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Carregar Dados e Executar\n",
    "\n",
    "# %%\n",
    "# Carregar datasets\n",
    "try:\n",
    "    df_existing = pd.read_csv('dados_com_odds.csv')\n",
    "    existing_ids = set(df_existing['event_id'])\n",
    "    logging.info(f\"Carregados {len(df_existing)} eventos existentes\")\n",
    "except FileNotFoundError:\n",
    "    df_existing = pd.DataFrame()\n",
    "    existing_ids = set()\n",
    "    logging.info(\"Arquivo não encontrado - iniciando do zero\")\n",
    "\n",
    "df_events = pd.read_csv('dados_eventos.csv')\n",
    "new_events = df_events[~df_events['event_id'].isin(existing_ids)]\n",
    "\n",
    "if new_events.empty:\n",
    "    logging.info(\"Nenhum novo evento para processar\")\n",
    "else:\n",
    "    logging.info(f\"Encontrados {len(new_events)} novos eventos\")\n",
    "\n",
    "# %%\n",
    "# Executar coleta com progresso\n",
    "results = []\n",
    "batch_size = 10  # Reduza se encontrar erros 429\n",
    "\n",
    "with tqdm(total=len(new_events), desc=\"Processando Odds\") as pbar:\n",
    "    with ThreadPoolExecutor(max_workers=3) as executor:\n",
    "        futures = {executor.submit(process_odds, row.event_id): row for _, row in new_events.iterrows()}\n",
    "        \n",
    "        for future in as_completed(futures):\n",
    "            if stop_execution:\n",
    "                executor.shutdown(wait=False, cancel_futures=True)\n",
    "                break\n",
    "                \n",
    "            result = future.result()\n",
    "            if result:\n",
    "                results.append(result)\n",
    "                pbar.update(1)\n",
    "                \n",
    "            # Salvar progresso a cada batch\n",
    "            if len(results) % batch_size == 0:\n",
    "                df_temp = pd.DataFrame(results)\n",
    "                if not df_temp.empty:\n",
    "                    df_final = pd.concat([df_existing, df_temp], ignore_index=True)\n",
    "                    df_final.to_csv('dados_com_odds.csv', index=False)\n",
    "                    logging.info(f\"Progresso salvo - {len(df_final)} eventos\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Salvamento Final e Resultados\n",
    "\n",
    "# %%\n",
    "# Consolidar dados finais\n",
    "if results:\n",
    "    df_final = pd.concat([df_existing, pd.DataFrame(results)], ignore_index=True)\n",
    "    df_final.to_csv('dados_com_odds.csv', index=False)\n",
    "    df_final.to_excel('dados_com_odds.xlsx', index=False)\n",
    "    logging.info(f\"Processo completo! Total de eventos: {len(df_final)}\")\n",
    "    \n",
    "    # Exibir amostra\n",
    "    display(df_final.tail(3))\n",
    "else:\n",
    "    logging.info(\"Nenhum novo dado foi processado\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
