{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r'featured_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>date</th>\n",
       "      <th>away_team</th>\n",
       "      <th>away_player</th>\n",
       "      <th>away_score</th>\n",
       "      <th>home_team</th>\n",
       "      <th>home_player</th>\n",
       "      <th>home_score</th>\n",
       "      <th>total_score</th>\n",
       "      <th>matchup_key</th>\n",
       "      <th>...</th>\n",
       "      <th>delta_std_10-3_home_pos</th>\n",
       "      <th>delta_std_10-3_away_pos</th>\n",
       "      <th>ewma_0.03</th>\n",
       "      <th>ewma_0.15</th>\n",
       "      <th>home_median</th>\n",
       "      <th>home_std</th>\n",
       "      <th>home_avg</th>\n",
       "      <th>away_median</th>\n",
       "      <th>away_std</th>\n",
       "      <th>away_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26879</th>\n",
       "      <td>9789983</td>\n",
       "      <td>2025-04-09 11:06:00</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>Bomb1to</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Wboy</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>('bomb1to', 'wboy')</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.314831</td>\n",
       "      <td>-0.094422</td>\n",
       "      <td>5.906765</td>\n",
       "      <td>5.383631</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.728876</td>\n",
       "      <td>2.989130</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.594433</td>\n",
       "      <td>2.826087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26880</th>\n",
       "      <td>9789984</td>\n",
       "      <td>2025-04-09 11:06:00</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Jekunam</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>Arcos</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>('arcos', 'jekunam')</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.228595</td>\n",
       "      <td>-0.076995</td>\n",
       "      <td>5.539631</td>\n",
       "      <td>5.574487</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.460268</td>\n",
       "      <td>2.551724</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.455873</td>\n",
       "      <td>2.770115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26881</th>\n",
       "      <td>9790070</td>\n",
       "      <td>2025-04-09 11:14:00</td>\n",
       "      <td>Man City</td>\n",
       "      <td>sane4ek8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Boca Juniors</td>\n",
       "      <td>labotryas</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>('labotryas', 'sane4ek8')</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.605628</td>\n",
       "      <td>-0.927063</td>\n",
       "      <td>4.912904</td>\n",
       "      <td>4.587610</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.254265</td>\n",
       "      <td>2.511278</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.159261</td>\n",
       "      <td>2.315789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26882</th>\n",
       "      <td>9790071</td>\n",
       "      <td>2025-04-09 11:14:00</td>\n",
       "      <td>PSG</td>\n",
       "      <td>Flewless_phoenix</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Real Madrid</td>\n",
       "      <td>FEARGGWP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>('fearggwp', 'flewless_phoenix')</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047219</td>\n",
       "      <td>-0.260536</td>\n",
       "      <td>4.329009</td>\n",
       "      <td>4.555433</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.380211</td>\n",
       "      <td>2.233871</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.259175</td>\n",
       "      <td>2.056452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26883</th>\n",
       "      <td>9789627</td>\n",
       "      <td>2025-04-09 11:38:00</td>\n",
       "      <td>Man City</td>\n",
       "      <td>sane4ek8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>PSG</td>\n",
       "      <td>Flewless_phoenix</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>('flewless_phoenix', 'sane4ek8')</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.306191</td>\n",
       "      <td>-0.800751</td>\n",
       "      <td>4.391331</td>\n",
       "      <td>4.242091</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.327684</td>\n",
       "      <td>2.385185</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.493948</td>\n",
       "      <td>2.318519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       event_id                 date    away_team       away_player  \\\n",
       "26879   9789983  2025-04-09 11:06:00  Netherlands           Bomb1to   \n",
       "26880   9789984  2025-04-09 11:06:00     Portugal           Jekunam   \n",
       "26881   9790070  2025-04-09 11:14:00     Man City          sane4ek8   \n",
       "26882   9790071  2025-04-09 11:14:00          PSG  Flewless_phoenix   \n",
       "26883   9789627  2025-04-09 11:38:00     Man City          sane4ek8   \n",
       "\n",
       "       away_score     home_team       home_player  home_score  total_score  \\\n",
       "26879         3.0        Sweden              Wboy         2.0          5.0   \n",
       "26880         1.0        Mexico             Arcos         3.0          4.0   \n",
       "26881         2.0  Boca Juniors         labotryas         2.0          4.0   \n",
       "26882         2.0   Real Madrid          FEARGGWP         0.0          2.0   \n",
       "26883         5.0           PSG  Flewless_phoenix         2.0          7.0   \n",
       "\n",
       "                            matchup_key  ...  delta_std_10-3_home_pos  \\\n",
       "26879               ('bomb1to', 'wboy')  ...                -0.314831   \n",
       "26880              ('arcos', 'jekunam')  ...                -0.228595   \n",
       "26881         ('labotryas', 'sane4ek8')  ...                -0.605628   \n",
       "26882  ('fearggwp', 'flewless_phoenix')  ...                 0.047219   \n",
       "26883  ('flewless_phoenix', 'sane4ek8')  ...                -0.306191   \n",
       "\n",
       "       delta_std_10-3_away_pos  ewma_0.03  ewma_0.15  home_median  home_std  \\\n",
       "26879                -0.094422   5.906765   5.383631          3.0  1.728876   \n",
       "26880                -0.076995   5.539631   5.574487          2.0  1.460268   \n",
       "26881                -0.927063   4.912904   4.587610          2.0  1.254265   \n",
       "26882                -0.260536   4.329009   4.555433          2.0  1.380211   \n",
       "26883                -0.800751   4.391331   4.242091          2.0  1.327684   \n",
       "\n",
       "       home_avg  away_median  away_std  away_avg  \n",
       "26879  2.989130          3.0  1.594433  2.826087  \n",
       "26880  2.551724          3.0  1.455873  2.770115  \n",
       "26881  2.511278          2.0  1.159261  2.315789  \n",
       "26882  2.233871          2.0  1.259175  2.056452  \n",
       "26883  2.385185          2.0  1.493948  2.318519  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = ['time_since_start', 'last_h2h', 'h2h_count', 'h2h_9h_count',\n",
    "       'is_return_match', 'l1', 'l2', 'l3', 'median_3', 'std_3', 'avg_3',\n",
    "       'median_10', 'std_10', 'avg_10', 'median_10_home_pos',\n",
    "       'std_10_home_pos', 'avg_10_home_pos', 'median_10_away_pos',\n",
    "       'std_10_away_pos', 'avg_10_away_pos', 'median_3_home_pos',\n",
    "       'std_3_home_pos', 'avg_3_home_pos', 'median_3_away_pos',\n",
    "       'std_3_away_pos', 'avg_3_away_pos', 'consistency_3_home_pos',\n",
    "       'consistency_3_away_pos', 'consistency_10_home_pos',\n",
    "       'consistency_10_away_pos', 'delta_avg_10-3_home_pos',\n",
    "       'delta_avg_10-3_away_pos', 'delta_std_10-3_home_pos',\n",
    "       'delta_std_10-3_away_pos', 'ewma_0.03', 'ewma_0.15', 'home_median',\n",
    "       'home_std', 'home_avg', 'away_median', 'away_std', 'away_avg',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[FEATURES].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      PC1       PC2       PC3       PC4       PC5       PC6  \\\n",
      "ewma_0.15        0.295385  0.008493  0.072676  0.033669  0.005388  0.023695   \n",
      "avg_10           0.278739  0.016558  0.098677  0.041152  0.006051  0.018004   \n",
      "median_10        0.260807  0.020732  0.086472  0.062678  0.005250  0.023804   \n",
      "away_avg         0.251744  0.057485  0.133237  0.028336  0.003842  0.040336   \n",
      "avg_3            0.250671  0.016114  0.028352  0.013621  0.004272  0.055615   \n",
      "home_avg         0.249554  0.000628  0.145860  0.026903  0.005374  0.013106   \n",
      "ewma_0.03        0.243545  0.018768  0.139738  0.025241  0.005065  0.002895   \n",
      "median_3         0.228660  0.012494  0.034289  0.036192  0.006126  0.055837   \n",
      "home_median      0.209325  0.001759  0.128178  0.049574  0.013536  0.038193   \n",
      "avg_10_away_pos  0.207919  0.218803  0.152964  0.016781  0.054886  0.003880   \n",
      "\n",
      "                      PC7       PC8       PC9      PC10  ...      PC33  \\\n",
      "ewma_0.15        0.062305  0.037116  0.009003  0.002322  ...  0.390671   \n",
      "avg_10           0.022341  0.045386  0.010383  0.006888  ...  0.264648   \n",
      "median_10        0.026052  0.069937  0.008832  0.011165  ...  0.420341   \n",
      "away_avg         0.219918  0.084191  0.011532  0.013958  ...  0.168187   \n",
      "avg_3            0.343083  0.025856  0.034120  0.040406  ...  0.435459   \n",
      "home_avg         0.227961  0.071670  0.056623  0.058965  ...  0.382710   \n",
      "ewma_0.03        0.191600  0.074083  0.039976  0.034537  ...  0.032527   \n",
      "median_3         0.343781  0.007679  0.029469  0.036037  ...  0.324554   \n",
      "home_median      0.215528  0.097237  0.059886  0.056694  ...  0.186104   \n",
      "avg_10_away_pos  0.080764  0.018576  0.144260  0.112394  ...  0.043271   \n",
      "\n",
      "                     PC34      PC35      PC36      PC37      PC38  \\\n",
      "ewma_0.15        0.178578  0.058316  0.016362  0.006861  0.792513   \n",
      "avg_10           0.139487  0.588422  0.025654  0.002166  0.456593   \n",
      "median_10        0.143254  0.434496  0.017117  0.004246  0.034301   \n",
      "away_avg         0.668820  0.074986  0.017589  0.018952  0.044203   \n",
      "avg_3            0.230339  0.569211  0.004444  0.018393  0.365217   \n",
      "home_avg         0.366108  0.057155  0.014384  0.002575  0.030394   \n",
      "ewma_0.03        0.026738  0.012716  0.011487  0.002461  0.099712   \n",
      "median_3         0.166966  0.300323  0.003598  0.007326  0.012227   \n",
      "home_median      0.230951  0.008922  0.004184  0.003777  0.001152   \n",
      "avg_10_away_pos  0.013774  0.007913  0.053618  0.527044  0.003502   \n",
      "\n",
      "                         PC39          PC40          PC41          PC42  \n",
      "ewma_0.15        1.045767e-14  6.759100e-15  7.422166e-15  2.882069e-15  \n",
      "avg_10           7.152482e-15  4.168175e-15  5.846536e-15  9.071198e-16  \n",
      "median_10        1.712053e-15  2.902489e-16  1.728133e-15  2.348632e-16  \n",
      "away_avg         1.060674e-15  9.111785e-16  3.913223e-16  4.942743e-18  \n",
      "avg_3            4.917684e-15  1.968278e-15  3.011199e-15  9.330774e-16  \n",
      "home_avg         2.183813e-15  4.089980e-16  1.629317e-17  3.096810e-15  \n",
      "ewma_0.03        6.721485e-16  1.075020e-15  7.312274e-16  1.908513e-15  \n",
      "median_3         4.855125e-17  8.838975e-16  2.858610e-16  7.469140e-16  \n",
      "home_median      1.249101e-15  2.457626e-16  2.563038e-16  1.632398e-15  \n",
      "avg_10_away_pos  7.128125e-03  6.487322e-02  5.991965e-02  4.406010e-01  \n",
      "\n",
      "[10 rows x 42 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 4. PCA\n",
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# 5. GrÃ¡fico de variÃ¢ncia explicada\n",
    "var_acum = pca.explained_variance_ratio_.cumsum()\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(range(1, len(var_acum)+1), var_acum, marker='o')\n",
    "plt.xlabel('NÃºmero de componentes')\n",
    "plt.ylabel('VariÃ¢ncia Explicada Acumulada')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 6. Loadings (cargas)\n",
    "loadings = pd.DataFrame(\n",
    "    pca.components_.T,\n",
    "    columns=[f'PC{i+1}' for i in range(len(FEATURES))],\n",
    "    index=FEATURES\n",
    ")\n",
    "print(loadings.abs().sort_values('PC1', ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['delta_ewma'] = df['ewma_0.03'] - df['ewma_0.15']\n",
    "df['delta_3vs10'] = df['avg_3'] - df['avg_10']\n",
    "df['dela_at'] = df['avg_10'] - (df['home_avg'] + df['away_avg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_FEATURES = [\n",
    "    'ewma_0.15', 'ewma_0.03',\n",
    "    'avg_10', 'median_10',\n",
    "    'avg_3', 'median_3',\n",
    "    'home_avg', 'away_avg',\n",
    "    'delta_ewma', 'delta_3vs10',\n",
    "    'delta_at'\n",
    "]\n",
    "\n",
    "ORIGINAL_DF = [\n",
    "    'event_id', 'date',\n",
    "    'away_team', 'away_player', 'away_score',\n",
    "    'home_team', 'home_player', 'home_score', 'total_score'\n",
    "]\n",
    "\n",
    "TARGET = ['total_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])\n",
    "split_date = datetime(2025, 3, 20)\n",
    "df_train = df[df['date'] < split_date]\n",
    "df_valid = df[df['date'] >= split_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WMAPE: 34.53%\n",
      "Poisson Deviance mÃ©dia: 0.9642\n",
      "RMSE: 2.0761\n"
     ]
    }
   ],
   "source": [
    "#Poisson Deviance, WMape\n",
    "#Baseline: Soma MÃ©dia Casa + MÃ©dia Fora\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_poisson_deviance, root_mean_squared_error\n",
    "\n",
    "def wmape(y_true, y_pred, eps=1e-8):\n",
    "    \"\"\"\n",
    "    Calcula o WMAPE entre y_true e y_pred.\n",
    "    eps evita divisÃ£o por zero quando sum(y_true)=0.\n",
    "    Retorna valor em %.\n",
    "    \"\"\"\n",
    "    num = np.abs(y_pred - y_true).sum()\n",
    "    den = y_true.sum()\n",
    "    return 100 * num / (den + eps)\n",
    "\n",
    "\n",
    "y_pred = df_train['home_avg'] + df_train['away_avg']\n",
    "y_true = df_train['total_score']\n",
    "rmse = root_mean_squared_error(y_true, y_pred)\n",
    "deviance = mean_poisson_deviance(y_true, y_pred)\n",
    "\n",
    "print(f\"WMAPE: {wmape(y_true, y_pred):.2f}%\")\n",
    "print(f\"Poisson Deviance mÃ©dia: {deviance:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[FEATURES]\n",
    "y_train = df_train['total_score']\n",
    "\n",
    "X_valid = df_valid[FEATURES]\n",
    "y_valid = df_valid['total_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "[CV 1/5; 1/500] START colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=150, subsample=0.6\n",
      "[CV 1/5; 1/500] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=150, subsample=0.6;, score=-2.184 total time=   0.2s\n",
      "[CV 2/5; 1/500] START colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=150, subsample=0.6\n",
      "[CV 2/5; 1/500] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=150, subsample=0.6;, score=-2.129 total time=   0.2s\n",
      "[CV 3/5; 1/500] START colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=150, subsample=0.6\n",
      "[CV 3/5; 1/500] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=150, subsample=0.6;, score=-2.214 total time=   0.2s\n",
      "[CV 4/5; 1/500] START colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=150, subsample=0.6\n",
      "[CV 4/5; 1/500] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=150, subsample=0.6;, score=-2.122 total time=   0.2s\n",
      "[CV 5/5; 1/500] START colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=150, subsample=0.6\n",
      "[CV 5/5; 1/500] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=150, subsample=0.6;, score=-2.249 total time=   0.3s\n",
      "[CV 1/5; 2/500] START colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=150, subsample=0.8\n",
      "[CV 1/5; 2/500] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=150, subsample=0.8;, score=-2.156 total time=   1.9s\n",
      "[CV 2/5; 2/500] START colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=150, subsample=0.8\n",
      "[CV 2/5; 2/500] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=150, subsample=0.8;, score=-2.144 total time=   1.9s\n",
      "[CV 3/5; 2/500] START colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=150, subsample=0.8\n",
      "[CV 3/5; 2/500] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=150, subsample=0.8;, score=-2.201 total time=   2.0s\n",
      "[CV 4/5; 2/500] START colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=150, subsample=0.8\n",
      "[CV 4/5; 2/500] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=150, subsample=0.8;, score=-2.130 total time=   1.9s\n",
      "[CV 5/5; 2/500] START colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=150, subsample=0.8\n",
      "[CV 5/5; 2/500] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=150, subsample=0.8;, score=-2.225 total time=   2.0s\n",
      "[CV 1/5; 3/500] START colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=150, subsample=0.8\n",
      "[CV 1/5; 3/500] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=150, subsample=0.8;, score=-2.172 total time=   0.2s\n",
      "[CV 2/5; 3/500] START colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=150, subsample=0.8\n",
      "[CV 2/5; 3/500] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=150, subsample=0.8;, score=-2.132 total time=   0.2s\n",
      "[CV 3/5; 3/500] START colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=150, subsample=0.8\n",
      "[CV 3/5; 3/500] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=150, subsample=0.8;, score=-2.181 total time=   0.2s\n",
      "[CV 4/5; 3/500] START colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=150, subsample=0.8\n",
      "[CV 4/5; 3/500] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=150, subsample=0.8;, score=-2.123 total time=   0.2s\n",
      "[CV 5/5; 3/500] START colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=150, subsample=0.8\n",
      "[CV 5/5; 3/500] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=150, subsample=0.8;, score=-2.220 total time=   0.2s\n",
      "[CV 1/5; 4/500] START colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=50, subsample=0.6\n",
      "[CV 1/5; 4/500] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=50, subsample=0.6;, score=-2.255 total time=   0.5s\n",
      "[CV 2/5; 4/500] START colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=50, subsample=0.6\n",
      "[CV 2/5; 4/500] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=50, subsample=0.6;, score=-2.213 total time=   0.5s\n",
      "[CV 3/5; 4/500] START colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=50, subsample=0.6\n",
      "[CV 3/5; 4/500] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=50, subsample=0.6;, score=-2.257 total time=   0.5s\n",
      "[CV 4/5; 4/500] START colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=50, subsample=0.6\n",
      "[CV 4/5; 4/500] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=50, subsample=0.6;, score=-2.222 total time=   0.5s\n",
      "[CV 5/5; 4/500] START colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=50, subsample=0.6\n",
      "[CV 5/5; 4/500] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=50, subsample=0.6;, score=-2.292 total time=   0.5s\n",
      "[CV 1/5; 5/500] START colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0\n",
      "[CV 1/5; 5/500] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0;, score=-2.152 total time=   2.2s\n",
      "[CV 2/5; 5/500] START colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0\n",
      "[CV 2/5; 5/500] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0;, score=-2.137 total time=   2.2s\n",
      "[CV 3/5; 5/500] START colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0\n",
      "[CV 3/5; 5/500] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0;, score=-2.205 total time=   2.2s\n",
      "[CV 4/5; 5/500] START colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0\n",
      "[CV 4/5; 5/500] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0;, score=-2.127 total time=   2.2s\n",
      "[CV 5/5; 5/500] START colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0\n",
      "[CV 5/5; 5/500] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0;, score=-2.232 total time=   2.2s\n",
      "[CV 1/5; 6/500] START colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=100, subsample=0.6\n",
      "[CV 1/5; 6/500] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=100, subsample=0.6;, score=-2.090 total time=   0.9s\n",
      "[CV 2/5; 6/500] START colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=100, subsample=0.6\n",
      "[CV 2/5; 6/500] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=100, subsample=0.6;, score=-2.095 total time=   1.0s\n",
      "[CV 3/5; 6/500] START colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=100, subsample=0.6\n",
      "[CV 3/5; 6/500] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=100, subsample=0.6;, score=-2.137 total time=   1.0s\n",
      "[CV 4/5; 6/500] START colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=100, subsample=0.6\n",
      "[CV 4/5; 6/500] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=100, subsample=0.6;, score=-2.066 total time=   1.0s\n",
      "[CV 5/5; 6/500] START colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=100, subsample=0.6\n",
      "[CV 5/5; 6/500] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=100, subsample=0.6;, score=-2.153 total time=   1.0s\n",
      "[CV 1/5; 7/500] START colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=50, subsample=1.0\n",
      "[CV 1/5; 7/500] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=50, subsample=1.0;, score=-2.064 total time=   0.0s\n",
      "[CV 2/5; 7/500] START colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=50, subsample=1.0\n",
      "[CV 2/5; 7/500] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=50, subsample=1.0;, score=-2.075 total time=   0.0s\n",
      "[CV 3/5; 7/500] START colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=50, subsample=1.0\n",
      "[CV 3/5; 7/500] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=50, subsample=1.0;, score=-2.104 total time=   0.0s\n",
      "[CV 4/5; 7/500] START colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=50, subsample=1.0\n",
      "[CV 4/5; 7/500] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=50, subsample=1.0;, score=-2.050 total time=   0.0s\n",
      "[CV 5/5; 7/500] START colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=50, subsample=1.0\n",
      "[CV 5/5; 7/500] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=50, subsample=1.0;, score=-2.116 total time=   0.0s\n",
      "[CV 1/5; 8/500] START colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.8\n",
      "[CV 1/5; 8/500] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.8;, score=-2.066 total time=   0.2s\n",
      "[CV 2/5; 8/500] START colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.8\n",
      "[CV 2/5; 8/500] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.8;, score=-2.074 total time=   0.2s\n",
      "[CV 3/5; 8/500] START colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.8\n",
      "[CV 3/5; 8/500] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.8;, score=-2.114 total time=   0.2s\n",
      "[CV 4/5; 8/500] START colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.8\n",
      "[CV 4/5; 8/500] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.8;, score=-2.050 total time=   0.3s\n",
      "[CV 5/5; 8/500] START colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.8\n",
      "[CV 5/5; 8/500] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.8;, score=-2.128 total time=   0.2s\n",
      "[CV 1/5; 9/500] START colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=150, subsample=0.8\n",
      "[CV 1/5; 9/500] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=150, subsample=0.8;, score=-2.092 total time=   0.2s\n",
      "[CV 2/5; 9/500] START colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=150, subsample=0.8\n",
      "[CV 2/5; 9/500] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=150, subsample=0.8;, score=-2.085 total time=   0.1s\n",
      "[CV 3/5; 9/500] START colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=150, subsample=0.8\n",
      "[CV 3/5; 9/500] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=150, subsample=0.8;, score=-2.126 total time=   0.2s\n",
      "[CV 4/5; 9/500] START colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=150, subsample=0.8\n",
      "[CV 4/5; 9/500] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=150, subsample=0.8;, score=-2.051 total time=   0.1s\n",
      "[CV 5/5; 9/500] START colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=150, subsample=0.8\n",
      "[CV 5/5; 9/500] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=150, subsample=0.8;, score=-2.137 total time=   0.1s\n",
      "[CV 1/5; 10/500] START colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.6\n",
      "[CV 1/5; 10/500] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.6;, score=-2.083 total time=   0.1s\n",
      "[CV 2/5; 10/500] START colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.6\n",
      "[CV 2/5; 10/500] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.6;, score=-2.074 total time=   0.1s\n",
      "[CV 3/5; 10/500] START colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.6\n",
      "[CV 3/5; 10/500] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.6;, score=-2.134 total time=   0.1s\n",
      "[CV 4/5; 10/500] START colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.6\n",
      "[CV 4/5; 10/500] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.6;, score=-2.062 total time=   0.1s\n",
      "[CV 5/5; 10/500] START colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.6\n",
      "[CV 5/5; 10/500] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.6;, score=-2.152 total time=   0.1s\n",
      "[CV 1/5; 11/500] START colsample_bytree=0.6, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.6\n",
      "[CV 1/5; 11/500] END colsample_bytree=0.6, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.6;, score=-2.187 total time=   0.2s\n",
      "[CV 2/5; 11/500] START colsample_bytree=0.6, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.6\n",
      "[CV 2/5; 11/500] END colsample_bytree=0.6, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.6;, score=-2.153 total time=   0.2s\n",
      "[CV 3/5; 11/500] START colsample_bytree=0.6, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.6\n",
      "[CV 3/5; 11/500] END colsample_bytree=0.6, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.6;, score=-2.216 total time=   0.2s\n",
      "[CV 4/5; 11/500] START colsample_bytree=0.6, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.6\n",
      "[CV 4/5; 11/500] END colsample_bytree=0.6, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.6;, score=-2.147 total time=   0.2s\n",
      "[CV 5/5; 11/500] START colsample_bytree=0.6, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.6\n",
      "[CV 5/5; 11/500] END colsample_bytree=0.6, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.6;, score=-2.278 total time=   0.2s\n",
      "[CV 1/5; 12/500] START colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.6\n",
      "[CV 1/5; 12/500] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.6;, score=-2.081 total time=   0.1s\n",
      "[CV 2/5; 12/500] START colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.6\n",
      "[CV 2/5; 12/500] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.6;, score=-2.088 total time=   0.1s\n",
      "[CV 3/5; 12/500] START colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.6\n",
      "[CV 3/5; 12/500] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.6;, score=-2.131 total time=   0.1s\n",
      "[CV 4/5; 12/500] START colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.6\n",
      "[CV 4/5; 12/500] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.6;, score=-2.061 total time=   0.1s\n",
      "[CV 5/5; 12/500] START colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.6\n",
      "[CV 5/5; 12/500] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.6;, score=-2.156 total time=   0.1s\n",
      "[CV 1/5; 13/500] START colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=100, subsample=0.8\n",
      "[CV 1/5; 13/500] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=100, subsample=0.8;, score=-2.087 total time=   1.0s\n",
      "[CV 2/5; 13/500] START colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=100, subsample=0.8\n",
      "[CV 2/5; 13/500] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=100, subsample=0.8;, score=-2.094 total time=   1.0s\n",
      "[CV 3/5; 13/500] START colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=100, subsample=0.8\n",
      "[CV 3/5; 13/500] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=100, subsample=0.8;, score=-2.140 total time=   1.0s\n",
      "[CV 4/5; 13/500] START colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=100, subsample=0.8\n",
      "[CV 4/5; 13/500] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=100, subsample=0.8;, score=-2.073 total time=   1.1s\n",
      "[CV 5/5; 13/500] START colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=100, subsample=0.8\n",
      "[CV 5/5; 13/500] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=100, subsample=0.8;, score=-2.165 total time=   1.1s\n",
      "[CV 1/5; 14/500] START colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.6\n",
      "[CV 1/5; 14/500] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.6;, score=-2.056 total time=   0.1s\n",
      "[CV 2/5; 14/500] START colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.6\n",
      "[CV 2/5; 14/500] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.6;, score=-2.068 total time=   0.1s\n",
      "[CV 3/5; 14/500] START colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.6\n",
      "[CV 3/5; 14/500] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.6;, score=-2.111 total time=   0.1s\n",
      "[CV 4/5; 14/500] START colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.6\n",
      "[CV 4/5; 14/500] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.6;, score=-2.044 total time=   0.1s\n",
      "[CV 5/5; 14/500] START colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.6\n",
      "[CV 5/5; 14/500] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.6;, score=-2.132 total time=   0.1s\n",
      "[CV 1/5; 15/500] START colsample_bytree=0.6, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0\n",
      "[CV 1/5; 15/500] END colsample_bytree=0.6, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0;, score=-2.227 total time=   2.1s\n",
      "[CV 2/5; 15/500] START colsample_bytree=0.6, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0\n",
      "[CV 2/5; 15/500] END colsample_bytree=0.6, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0;, score=-2.192 total time=   2.0s\n",
      "[CV 3/5; 15/500] START colsample_bytree=0.6, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0\n",
      "[CV 3/5; 15/500] END colsample_bytree=0.6, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0;, score=-2.231 total time=   2.2s\n",
      "[CV 4/5; 15/500] START colsample_bytree=0.6, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0\n",
      "[CV 4/5; 15/500] END colsample_bytree=0.6, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0;, score=-2.181 total time=   2.2s\n",
      "[CV 5/5; 15/500] START colsample_bytree=0.6, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[87]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     12\u001b[39m model = XGBRegressor(objective=\u001b[33m'\u001b[39m\u001b[33mreg:squarederror\u001b[39m\u001b[33m'\u001b[39m, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m     13\u001b[39m random_search = RandomizedSearchCV(\n\u001b[32m     14\u001b[39m     estimator=model,\n\u001b[32m     15\u001b[39m     param_distributions=param_dist,\n\u001b[32m   (...)\u001b[39m\u001b[32m     18\u001b[39m     verbose=\u001b[32m10\u001b[39m\n\u001b[32m     19\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[43mrandom_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m best_model = random_search.best_estimator_\n\u001b[32m     25\u001b[39m best_model.fit(X_train, y_train)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Enzo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Enzo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1018\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1019\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1020\u001b[39m     )\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1027\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1028\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Enzo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1951\u001b[39m, in \u001b[36mRandomizedSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1949\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1950\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1951\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1952\u001b[39m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1953\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_state\u001b[49m\n\u001b[32m   1954\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1955\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Enzo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    962\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    963\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    964\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    965\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    966\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    967\u001b[39m         )\n\u001b[32m    968\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m970\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    988\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m    989\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    990\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    993\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Enzo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Enzo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1916\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1917\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1918\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1920\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1921\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1922\u001b[39m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1923\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1924\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1925\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Enzo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1845\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1846\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1847\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1848\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1849\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Enzo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\parallel.py:139\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    137\u001b[39m     config = {}\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config):\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Enzo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:866\u001b[39m, in \u001b[36m_fit_and_score\u001b[39m\u001b[34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[39m\n\u001b[32m    864\u001b[39m         estimator.fit(X_train, **fit_params)\n\u001b[32m    865\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m866\u001b[39m         \u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[32m    870\u001b[39m     fit_time = time.time() - start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Enzo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:726\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    724\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    725\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m726\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Enzo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\sklearn.py:1170\u001b[39m, in \u001b[36mXGBModel.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[39m\n\u001b[32m   1167\u001b[39m     obj = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1169\u001b[39m model, metric, params = \u001b[38;5;28mself\u001b[39m._configure_fit(xgb_model, params)\n\u001b[32m-> \u001b[39m\u001b[32m1170\u001b[39m \u001b[38;5;28mself\u001b[39m._Booster = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1174\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1175\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1177\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1178\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1179\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1180\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1181\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1184\u001b[39m \u001b[38;5;28mself\u001b[39m._set_evaluation_result(evals_result)\n\u001b[32m   1185\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Enzo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:726\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    724\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    725\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m726\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Enzo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:181\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[39m\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.before_iteration(bst, i, dtrain, evals):\n\u001b[32m    180\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m \u001b[43mbst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.after_iteration(bst, i, dtrain, evals):\n\u001b[32m    183\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Enzo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:2101\u001b[39m, in \u001b[36mBooster.update\u001b[39m\u001b[34m(self, dtrain, iteration, fobj)\u001b[39m\n\u001b[32m   2097\u001b[39m \u001b[38;5;28mself\u001b[39m._assign_dmatrix_features(dtrain)\n\u001b[32m   2099\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2100\u001b[39m     _check_call(\n\u001b[32m-> \u001b[39m\u001b[32m2101\u001b[39m         \u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2102\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\n\u001b[32m   2103\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2104\u001b[39m     )\n\u001b[32m   2105\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2106\u001b[39m     pred = \u001b[38;5;28mself\u001b[39m.predict(dtrain, output_margin=\u001b[38;5;28;01mTrue\u001b[39;00m, training=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "model = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=500,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    verbose=10\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = df_valid['total_score']\n",
    "y_pred = best_model.predict(X_valid)\n",
    "rmse = root_mean_squared_error(y_true, y_pred)\n",
    "deviance = mean_poisson_deviance(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WMAPE: 33.84%\n",
      "Poisson Deviance mÃ©dia: 0.9546\n",
      "RMSE: 2.1202\n"
     ]
    }
   ],
   "source": [
    "print(f\"WMAPE: {wmape(y_true, y_pred):.2f}%\")\n",
    "print(f\"Poisson Deviance mÃ©dia: {deviance:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
